{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.10/site-packages/thinc/shims/pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n",
      "/home/neo/environments/text2graphs/venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"You are an expert Named Entity Recognition (NER) system.\\nYour task is to accept Text as input and extract named entities.\\nEntities must have one of the following labels: DISH, EQUIPMENT, INGREDIENT, LOCATION, PERSON.\\nIf a span is not an entity label it: `==NONE==`.\\n\\n\\nEntities are the names food dishes,\\ningredients, and any kind of cooking equipment.\\nAdjectives, verbs, adverbs are not entities.\\nPronouns are not entities. Please extract all the entities as per the labels and don't enclose the extracted entities with *\\nBelow are definitions of each label to help aid you in what kinds of named entities to extract for each label.\\nAssume these definitions are written by an expert and follow them closely.\\nDISH: Known food dishes, e.g. Lobster Ravioli, garlic bread\\nINGREDIENT: Individual parts of a food dish, including herbs and spices.\\nEQUIPMENT: Any kind of cooking equipment. e.g. oven, cooking pot, grill\\n\\nQ: Given the paragraph below, identify a list of entities, and for each entry explain why it is or is not an entity:\\n\\nParagraph: You can't get a great chocolate flavor with carob.\\nAnswer:\\n1. chocolate | False | ==NONE== | is a flavor in this context, not an ingredient\\n2. carob | True | INGREDIENT | is an ingredient to add chocolate flavor\\n\\nParagraph: You can probably sand-blast it if it's an anodized aluminum pan\\nAnswer:\\n1. sand-blast | False | ==NONE== | is a cleaning technique, not some kind of equipment\\n2. anodized aluminum pan | True | EQUIPMENT | is a piece of cooking equipment, anodized is included since it describes the type of pan\\n\\nParagraph: “These numbers are alarming, and actions need to be taken because not enough new talent is coming through.”To be competitive in AI, Griggs said we need to start integrating it nationally into school curriculums, training programs, and any other field of study because it’s already a necessary tool.\\nAnswer:\"]\n",
      "[\"You are an expert Named Entity Recognition (NER) system.\\nYour task is to accept Text as input and extract named entities.\\nEntities must have one of the following labels: DISH, EQUIPMENT, INGREDIENT, LOCATION, PERSON.\\nIf a span is not an entity label it: `==NONE==`.\\n\\n\\nEntities are the names food dishes,\\ningredients, and any kind of cooking equipment.\\nAdjectives, verbs, adverbs are not entities.\\nPronouns are not entities. Please extract all the entities as per the labels and don't enclose the extracted entities with *\\nBelow are definitions of each label to help aid you in what kinds of named entities to extract for each label.\\nAssume these definitions are written by an expert and follow them closely.\\nDISH: Known food dishes, e.g. Lobster Ravioli, garlic bread\\nINGREDIENT: Individual parts of a food dish, including herbs and spices.\\nEQUIPMENT: Any kind of cooking equipment. e.g. oven, cooking pot, grill\\n\\nQ: Given the paragraph below, identify a list of entities, and for each entry explain why it is or is not an entity:\\n\\nParagraph: You can't get a great chocolate flavor with carob.\\nAnswer:\\n1. chocolate | False | ==NONE== | is a flavor in this context, not an ingredient\\n2. carob | True | INGREDIENT | is an ingredient to add chocolate flavor\\n\\nParagraph: You can probably sand-blast it if it's an anodized aluminum pan\\nAnswer:\\n1. sand-blast | False | ==NONE== | is a cleaning technique, not some kind of equipment\\n2. anodized aluminum pan | True | EQUIPMENT | is a piece of cooking equipment, anodized is included since it describes the type of pan\\n\\nParagraph: “These numbers are alarming, and actions need to be taken because not enough new talent is coming through.”To be competitive in AI, Griggs said we need to start integrating it nationally into school curriculums, training programs, and any other field of study because it’s already a necessary tool.\\nAnswer:\"]\n",
      "['The text below contains pre-extracted entities, denoted in the following format within the text:\\n\\n<entity text>[ENT<entity id>:<entity label>]\\n\\nFrom the text below, extract the following relations between entities:\\n\\nLivesIn\\nVisits\\n\\nThe extraction has to use the following format, with one line for each detected relation:\\n\\n{\"dep\": <entity id>, \"dest\": <entity id>, \"relation\": <relation label>}\\n\\nMake sure that only relevant relations are listed, and that each line is a valid JSON object.\\nHere is the text that needs labeling:\\n\\nText:\\n\\'\\'\\'\\n“These numbers are alarming, and actions need to be taken because not enough new talent[ENT0:INGREDIENT] is coming through.”To be competitive in AI, Griggs[ENT1:PERSON] said we need to start integrating it nationally into school curriculums[ENT2:LOCATION], training programs[ENT3:LOCATION], and any other field of study[ENT4:LOCATION] because it’s already a necessary tool.\\n\\'\\'\\'']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.10/site-packages/spacy_llm/tasks/ner/util.py:48: UserWarning: [W101] Skipping Doc custom extension 'trf_data' while merging docs.\n",
      "  return Doc.from_docs(list(shards), ensure_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The text below contains pre-extracted entities, denoted in the following format within the text:\\n\\n<entity text>[ENT<entity id>:<entity label>]\\n\\nFrom the text below, extract the following relations between entities:\\n\\nLivesIn\\nVisits\\n\\nThe extraction has to use the following format, with one line for each detected relation:\\n\\n{\"dep\": <entity id>, \"dest\": <entity id>, \"relation\": <relation label>}\\n\\nMake sure that only relevant relations are listed, and that each line is a valid JSON object.\\nHere is the text that needs labeling:\\n\\nText:\\n\\'\\'\\'\\n“These numbers are alarming, and actions need to be taken because not enough new talent[ENT0:INGREDIENT] is coming through.”To be competitive in AI, Griggs[ENT1:PERSON] said we need to start integrating it nationally into school curriculums[ENT2:LOCATION], training programs[ENT3:LOCATION], and any other field of study[ENT4:LOCATION] because it’s already a necessary tool.\\n\\'\\'\\'']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m nlp \u001b[38;5;241m=\u001b[39m assemble(config_path\u001b[38;5;241m=\u001b[39mconfig_path, overrides\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths.examples\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(examples_path)})\n\u001b[1;32m     12\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m“These numbers are alarming, and actions need to be taken because not enough new talent is coming through.”To be competitive in AI, Griggs said we need to start integrating it nationally into school curriculums, training programs, and any other field of study because it’s already a necessary tool.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m******sentence: \u001b[39m\u001b[38;5;124m\"\u001b[39m, sent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m******\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/environments/text2graphs/venv/lib/python3.10/site-packages/spacy/tokens/doc.pyx:926\u001b[0m, in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_llm.util import assemble\n",
    "from spacy_llm.registry import registry\n",
    "from text_processing_components.llm.registry import openai_llama_3_1_8b\n",
    "\n",
    "\n",
    "config_path=\"/home/neo/environments/text2graphs/textgraphx/config.cfg\"  # Default value provided for config_path argument\n",
    "examples_path=\"/home/neo/environments/text2graphs/textgraphx/examples.json\" \n",
    "\n",
    "nlp = assemble(config_path=config_path, overrides={\"paths.examples\": str(examples_path)})\n",
    "\n",
    "doc = nlp(\"\"\"“These numbers are alarming, and actions need to be taken because not enough new talent is coming through.”To be competitive in AI, Griggs said we need to start integrating it nationally into school curriculums, training programs, and any other field of study because it’s already a necessary tool.\"\"\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(\"******sentence: \", sent, \"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.4\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(spacy.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
